{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../src')))\n",
    "from utils.statistical_analysis import correlation_analysis_resample\n",
    "from utils.statistical_analysis import filter_by_session_nyc\n",
    "from utils.holiday_utils import extract_weekday\n",
    "notebook_path = os.path.abspath(os.path.join(os.getcwd(), '../notebooks'))\n",
    "output_file_path = rf'{notebook_path}\\output\\correlation_analysis'\n",
    "output_session_filepath = rf'{notebook_path}\\data\\processed\\session'\n",
    "input_file_path = rf'{notebook_path}\\data\\processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering session: ny_morning\n",
      "Filtered rows for ny_morning:\n",
      "                           tick_number   price  actual_openprice  ticks_moved  \\\n",
      "datetime                                                                        \n",
      "2022-01-03 08:29:00-05:00            9  1.1359           1.13602            1   \n",
      "2022-01-03 08:43:00-05:00           10  1.1349           1.13480            1   \n",
      "2022-01-03 09:15:00-05:00           11  1.1339           1.13384            1   \n",
      "2022-01-03 09:21:00-05:00           12  1.1329           1.13289            1   \n",
      "2022-01-03 09:50:00-05:00           13  1.1319           1.13171            1   \n",
      "...                                ...     ...               ...          ...   \n",
      "2022-12-30 09:55:00-05:00         8284  1.0689           1.06918            1   \n",
      "2022-12-30 10:06:00-05:00         8285  1.0679           1.06744            1   \n",
      "2022-12-30 10:47:00-05:00         8286  1.0669           1.06660            1   \n",
      "2022-12-30 11:06:00-05:00         8287  1.0679           1.06798            1   \n",
      "2022-12-30 11:57:00-05:00         8288  1.0689           1.06895            1   \n",
      "\n",
      "                           directions  fx_return day_of_week  \n",
      "datetime                                                      \n",
      "2022-01-03 08:29:00-05:00           1   0.099569      Monday  \n",
      "2022-01-03 08:43:00-05:00          -1  -0.107392      Monday  \n",
      "2022-01-03 09:15:00-05:00          -1  -0.084596      Monday  \n",
      "2022-01-03 09:21:00-05:00          -1  -0.083786      Monday  \n",
      "2022-01-03 09:50:00-05:00          -1  -0.104158      Monday  \n",
      "...                               ...        ...         ...  \n",
      "2022-12-30 09:55:00-05:00           1   0.122674      Friday  \n",
      "2022-12-30 10:06:00-05:00          -1  -0.162742      Friday  \n",
      "2022-12-30 10:47:00-05:00          -1  -0.078693      Friday  \n",
      "2022-12-30 11:06:00-05:00           1   0.129383      Friday  \n",
      "2022-12-30 11:57:00-05:00           1   0.090826      Friday  \n",
      "\n",
      "[2890 rows x 7 columns]\n",
      "Filtered data saved to c:\\Users\\mmori\\Documents\\fx_strategy_project\\notebooks\\data\\processed\\session/2022_eurusd_ny_morning_tick_prev_price_as_base.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Filters the DataFrame by the given trading session or sub-session using NYC time as a base.\n",
    "   \n",
    "    Trading session/sub-session times (NYC time):\n",
    "    - asian: 19:00 (prev day) - 04:00\n",
    "    - asian_morning: 19:00 (prev day) - 01:00\n",
    "    - london: 03:00 - 12:00\n",
    "    - london_morning: 03:00 - 07:00\n",
    "    - london_afternoon: 07:00 - 12:00\n",
    "    - ny: 08:00 - 17:00\n",
    "    - ny_morning: 08:00 - 12:00\n",
    "    - ny_evening: 12:00 - 17:00\n",
    "   \n",
    "    Parameters:\n",
    "        df (DataFrame): The input time series DataFrame (with NYC timezone-aware timestamps).\n",
    "        session (str): The trading session or sub-session ('asian', 'london_morning', etc.).\n",
    "        output_file (str): Path to save the filtered DataFrame as a CSV file. If None, no file is saved.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Filtered DataFrame for the session.\n",
    "\"\"\"\n",
    "%debug\n",
    "year = \"2022\"\n",
    "ccy = \"eurusd\"\n",
    "session = \"ny_morning\"\n",
    "base_price = \"prev\"\n",
    "\n",
    "file_path = rf'{input_file_path}/{year}_{ccy}_tick_{base_price}_price_as_base.csv'\n",
    "output_filepath = rf'{output_session_filepath}/{year}_{ccy}_{session}_tick_{base_price}_price_as_base.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "filtered_df = filter_by_session_nyc(df, session, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug\n",
    "year = \"2023\"\n",
    "ccy = \"eurgbp\"\n",
    "sessions = [\"ny\", \"ny_morning\", \"ny_evening\", \"london\", \"london_morning\", \"london_afternoon\", \"asian\", \"asian_morning\"]\n",
    "base_price = \"prev\"\n",
    "\n",
    "for session in sessions:\n",
    "    file_path = rf'{input_file_path}/{year}_{ccy}_tick_{base_price}_price_as_base.csv'\n",
    "    output_filepath = rf'{output_session_filepath}/{year}_{ccy}_{session}_tick_{base_price}_price_as_base.csv'\n",
    "\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    filtered_df = filter_by_session_nyc(df, session, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with 'Monday' in the 'day_of_week' column have been extracted.\n",
      "Filtered data saved to: c:\\Users\\mmori\\Documents\\fx_strategy_project\\notebooks\\data\\processed\\session/2023_eurgbp_tick_prev_price_as_base_Monday.csv\n",
      "Rows with 'Tuesday' in the 'day_of_week' column have been extracted.\n",
      "Filtered data saved to: c:\\Users\\mmori\\Documents\\fx_strategy_project\\notebooks\\data\\processed\\session/2023_eurgbp_tick_prev_price_as_base_Tuesday.csv\n",
      "Rows with 'Wednesday' in the 'day_of_week' column have been extracted.\n",
      "Filtered data saved to: c:\\Users\\mmori\\Documents\\fx_strategy_project\\notebooks\\data\\processed\\session/2023_eurgbp_tick_prev_price_as_base_Wednesday.csv\n",
      "Rows with 'Thursday' in the 'day_of_week' column have been extracted.\n",
      "Filtered data saved to: c:\\Users\\mmori\\Documents\\fx_strategy_project\\notebooks\\data\\processed\\session/2023_eurgbp_tick_prev_price_as_base_Thursday.csv\n",
      "Rows with 'Friday' in the 'day_of_week' column have been extracted.\n",
      "Filtered data saved to: c:\\Users\\mmori\\Documents\\fx_strategy_project\\notebooks\\data\\processed\\session/2023_eurgbp_tick_prev_price_as_base_Friday.csv\n"
     ]
    }
   ],
   "source": [
    "year = \"2023\"\n",
    "ccy = \"eurgbp\"\n",
    "use_first_price_as_base=False # True: use first price as base, False: use previous price as base\n",
    "weekdays = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]\n",
    "base_price = \"prev\"\n",
    "\n",
    "for day_of_week in weekdays:\n",
    "    if (use_first_price_as_base):\n",
    "        input_filename = f'{input_file_path}/{year}_{ccy.lower()}_tick_first_price_as_base.csv'\n",
    "        output_filename = f'{output_session_filepath}/{year}_{ccy.lower()}_tick_first_price_as_base_{day_of_week}.csv'\n",
    "    else:\n",
    "        input_filename = f'{input_file_path}/{year}_{ccy.lower()}_tick_prev_price_as_base.csv'\n",
    "        output_filename = f'{output_session_filepath}/{year}_{ccy.lower()}_tick_prev_price_as_base_{day_of_week}.csv'\n",
    "    extract_weekday(input_filename, output_filename, day_of_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          datetime      open      high       low     close  volume\n",
      "0  20230102 180000  3872.998  3877.176  3863.860  3865.983       0\n",
      "1  20230102 180100  3866.128  3867.372  3865.378  3865.980       0\n",
      "2  20230102 180200  3865.878  3866.878  3865.360  3865.881       0\n",
      "3  20230102 180300  3865.742  3865.742  3862.860  3863.613       0\n",
      "4  20230102 180400  3863.363  3863.363  3860.742  3860.878       0\n",
      "          datetime     open     high      low    close  volume\n",
      "0  20230101 170000  130.925  130.925  130.910  130.921       0\n",
      "1  20230101 170100  130.921  130.962  130.921  130.960       0\n",
      "2  20230101 170200  130.960  130.960  130.959  130.959       0\n",
      "3  20230101 170400  130.943  130.943  130.808  130.820       0\n",
      "4  20230101 170500  130.825  130.825  130.814  130.814       0\n",
      "             datetime  open_spxusd  high_spxusd  low_spxusd  close_spxusd  \\\n",
      "0 2023-01-02 18:00:00     3872.998     3877.176    3863.860      3865.983   \n",
      "1 2023-01-02 18:01:00     3866.128     3867.372    3865.378      3865.980   \n",
      "2 2023-01-02 18:02:00     3865.878     3866.878    3865.360      3865.881   \n",
      "3 2023-01-02 18:03:00     3865.742     3865.742    3862.860      3863.613   \n",
      "4 2023-01-02 18:04:00     3863.363     3863.363    3860.742      3860.878   \n",
      "\n",
      "   volume_spxusd  open_usdjpy  high_usdjpy  low_usdjpy  close_usdjpy  \\\n",
      "0              0      130.699      130.832     130.699       130.759   \n",
      "1              0      130.759      130.797     130.690       130.747   \n",
      "2              0      130.747      130.760     130.692       130.757   \n",
      "3              0      130.749      130.762     130.700       130.734   \n",
      "4              0      130.734      130.737     130.670       130.690   \n",
      "\n",
      "   volume_usdjpy  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "-0.007286576437847909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-0.007286576437847909)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = \"2023\"\n",
    "target_ccy = \"usdjpy\"\n",
    "feature_ccy = \"spxusd\"\n",
    "\n",
    "target_filepath = rf'{notebook_path}\\data\\ASCII\\M1\\{target_ccy.lower()}\\{year}\\DAT_ASCII_{target_ccy.upper()}_M1_{year}.csv'\n",
    "feature_filepath = rf'{notebook_path}\\data\\ASCII\\M1\\{feature_ccy.lower()}\\{year}\\DAT_ASCII_{feature_ccy.upper()}_M1_{year}.csv'\n",
    "correlation_analysis_resample(target_filepath, feature_filepath, target_ccy, feature_ccy, year, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          datetime      open      high       low     close  volume\n",
      "0  20230102 180000  3872.998  3877.176  3863.860  3865.983       0\n",
      "1  20230102 180100  3866.128  3867.372  3865.378  3865.980       0\n",
      "2  20230102 180200  3865.878  3866.878  3865.360  3865.881       0\n",
      "3  20230102 180300  3865.742  3865.742  3862.860  3863.613       0\n",
      "4  20230102 180400  3863.363  3863.363  3860.742  3860.878       0\n",
      "          datetime     open     high      low    close  volume\n",
      "0  20230101 170000  130.925  130.925  130.910  130.921       0\n",
      "1  20230101 170100  130.921  130.962  130.921  130.960       0\n",
      "2  20230101 170200  130.960  130.960  130.959  130.959       0\n",
      "3  20230101 170400  130.943  130.943  130.808  130.820       0\n",
      "4  20230101 170500  130.825  130.825  130.814  130.814       0\n",
      "             datetime  open_spxusd  high_spxusd  low_spxusd  close_spxusd  \\\n",
      "0 2023-01-02 18:00:00     3872.998     3877.176    3846.110      3848.610   \n",
      "1 2023-01-02 19:00:00     3848.381     3848.872    3833.360      3833.860   \n",
      "2 2023-01-02 20:00:00     3834.122     3834.122    3820.110      3830.628   \n",
      "3 2023-01-02 21:00:00     3830.233     3840.631    3828.113      3838.616   \n",
      "4 2023-01-02 22:00:00     3838.875     3844.875    3837.119      3843.860   \n",
      "\n",
      "   volume_spxusd  open_usdjpy  high_usdjpy  low_usdjpy  close_usdjpy  \\\n",
      "0              0      130.699      131.403     130.535       130.790   \n",
      "1              0      130.789      130.903     130.570       130.606   \n",
      "2              0      130.612      130.714     129.807       130.148   \n",
      "3              0      130.150      130.305     129.780       129.920   \n",
      "4              0      129.922      129.982     129.678       129.782   \n",
      "\n",
      "   volume_usdjpy  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "0.033394218261811784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mmori\\Documents\\fx_strategy_project\\src\\utils\\statistical_analysis.py:22: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  feature_data = feature_data.resample(resample_interval).agg({\n",
      "c:\\Users\\mmori\\Documents\\fx_strategy_project\\src\\utils\\statistical_analysis.py:30: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  target_data = target_data.resample(resample_interval).agg({\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.033394218261811784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = \"2023\"\n",
    "target_ccy = \"usdjpy\"\n",
    "feature_ccy = \"spxusd\"\n",
    "resample_interval = \"1H\"\n",
    "\n",
    "target_filepath = rf'C:\\Users\\mmori\\Documents\\fx_strategy_project\\notebooks\\data\\raw\\ASCII\\M1\\{target_ccy.lower()}\\{year}\\DAT_ASCII_{target_ccy.upper()}_M1_{year}.csv'\n",
    "feature_filepath = rf'C:\\Users\\mmori\\Documents\\fx_strategy_project\\notebooks\\data\\raw\\ASCII\\M1\\{feature_ccy.lower()}\\{year}\\DAT_ASCII_{feature_ccy.upper()}_M1_{year}.csv'\n",
    "correlation_analysis_resample(target_filepath, feature_filepath, target_ccy, feature_ccy, year, output_file_path, resample_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          datetime      open      high       low     close  volume\n",
      "0  20230102 180000  3872.998  3877.176  3863.860  3865.983       0\n",
      "1  20230102 180100  3866.128  3867.372  3865.378  3865.980       0\n",
      "2  20230102 180200  3865.878  3866.878  3865.360  3865.881       0\n",
      "3  20230102 180300  3865.742  3865.742  3862.860  3863.613       0\n",
      "4  20230102 180400  3863.363  3863.363  3860.742  3860.878       0\n",
      "          datetime     open     high      low    close  volume\n",
      "0  20230101 170000  130.925  130.925  130.910  130.921       0\n",
      "1  20230101 170100  130.921  130.962  130.921  130.960       0\n",
      "2  20230101 170200  130.960  130.960  130.959  130.959       0\n",
      "3  20230101 170400  130.943  130.943  130.808  130.820       0\n",
      "4  20230101 170500  130.825  130.825  130.814  130.814       0\n",
      "    datetime  open_spxusd  high_spxusd  low_spxusd  close_spxusd  \\\n",
      "0 2023-01-02     3872.998     3877.176    3820.110      3841.381   \n",
      "1 2023-01-03     3841.116     3883.863    3792.915      3831.046   \n",
      "2 2023-01-04     3831.425     3873.492    3814.321      3850.013   \n",
      "3 2023-01-05     3850.326     3862.799    3801.950      3826.188   \n",
      "4 2023-01-06     3825.929     3906.079    3798.230      3891.369   \n",
      "\n",
      "   volume_spxusd  open_usdjpy  high_usdjpy  low_usdjpy  close_usdjpy  \\\n",
      "0              0      130.911      131.403     129.507       129.592   \n",
      "1              0      129.592      131.466     129.550       130.827   \n",
      "2              0      130.827      132.715     129.923       132.307   \n",
      "3              0      132.307      134.053     132.243       133.912   \n",
      "4              0      133.911      134.773     131.993       132.030   \n",
      "\n",
      "   volume_usdjpy  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "0.07069216151295275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.07069216151295275)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = \"2023\"\n",
    "target_ccy = \"usdjpy\"\n",
    "feature_ccy = \"spxusd\"\n",
    "resample_interval = \"1D\"\n",
    "\n",
    "target_filepath = rf'C:\\Users\\mmori\\Documents\\fx_strategy_project\\notebooks\\data\\raw\\ASCII\\M1\\{target_ccy.lower()}\\{year}\\DAT_ASCII_{target_ccy.upper()}_M1_{year}.csv'\n",
    "feature_filepath = rf'C:\\Users\\mmori\\Documents\\fx_strategy_project\\notebooks\\data\\raw\\ASCII\\M1\\{feature_ccy.lower()}\\{year}\\DAT_ASCII_{feature_ccy.upper()}_M1_{year}.csv'\n",
    "correlation_analysis_resample(target_filepath, feature_filepath, target_ccy, feature_ccy, year, output_file_path, resample_interval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fx_strategy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
